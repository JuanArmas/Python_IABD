# -*- coding: utf-8 -*-
"""Regresión lineal con Python_JuanArmas.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11dazZPJKYC9VIVSipYJB93M98hPSrqsE

<H3>Apartado 1.

Modifica el código usando los datos del archivo adjunto y muestra los puntos
junto con la recta de regresión usando el modelo de scikit-learn
"""

import matplotlib.pyplot as plt
import numpy as np

from sklearn import datasets, linear_model
from sklearn.metrics import mean_squared_error, r2_score

# Load the diabetes dataset
diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)

# diabetes_X = [2,6,8,8,12,16,20,20,22,26]
# diabetes_y = [58,105,88,118,117,137,157,169,149,202]

diabetes_X = diabetes_X[:, np.newaxis, 2]
diabetes_X = [[2],[6],[8],[8],[12],[16],[20],[20],[22],[26]]
diabetes_y = [[58],[105],[88],[118],[117],[137],[157],[169],[149],[202]]

# Split the data into training/testing sets
diabetes_X_train = diabetes_X[:7]
diabetes_X_test = diabetes_X[-7:]

# Split the targets into training/testing sets
diabetes_y_train = diabetes_y[:7]
diabetes_y_test = diabetes_y[-7:]

# Create linear regression object
regr = linear_model.LinearRegression()

# Train the model using the training sets
regr.fit(diabetes_X_train, diabetes_y_train)

# Make predictions using the testing set
diabetes_y_pred = regr.predict(diabetes_X_test)

# The coefficients
print("Coefficients: \n", regr.coef_)
# The mean squared error
print("Mean squared error: %.2f" % mean_squared_error(diabetes_y_test, diabetes_y_pred))
# The coefficient of determination: 1 is perfect prediction
print("Coefficient of determination: %.2f" % r2_score(diabetes_y_test, diabetes_y_pred))

# Plot outputs
plt.scatter(diabetes_X_test, diabetes_y_test, color="black")
plt.plot(diabetes_X_test, diabetes_y_pred, color="blue", linewidth=3)

plt.xticks(())
plt.yticks(())

plt.show()

"""...

<H3>Apartado 2.

Calcula la recta de regresión usando las fórmulas y dibújala con matplotlib
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn import linear_model
from sklearn.linear_model import LinearRegression

#creamos matrices multidimensionales con numpy para evitar problemas futuros de dimensionado.
x = np.array([[2], [6], [8], [8], [12], [16], [20], [20], [22], [26]])
y = np.array([[58], [105], [88], [118], [117], [137], [157], [169], [149], [202]])

longitud_x = len(x)
media_x = 0
media_y = 0
total_1 = 0
total_2 = 0

# Hallamos la media de la x
media_x = np.mean(x)
media_y = np.mean(y)


# Calculamos total_1 y total_2
for i in range(longitud_x):
    total_1 += (x[i][0] - media_x) * (y[i][0] - media_y)
    total_2 += (x[i][0] - media_x) ** 2

# S = ¿Recta de regresión lineal, inclinación o pendiente?
pendiente = total_1 / total_2

#b0 punto de salida de la linea en el eje Y
b0 = media_y - pendiente * media_x

#ŷ = b0 + b1 x Expresion para levantar la linea.
Linea = b0 + pendiente * x



# Graficar los datos y la línea de regresión
plt.scatter(x, y, color="black")
plt.plot(x, Linea, color='blue', linewidth=2)
plt.show()

"""..

..

<H1> Apartado 3:

Calcula los coeficientes de determinación r2 y r.
"""

# Cálculo de R^2
#suma_de_Cuadrados_total
SCT = np.sum((y - media_y) ** 2)
#Suma de cuadrados debida al error
SCE  = np.sum((y - Linea) ** 2)
#Coeficiente de determinación:
r_cuadrado = 1 - (SCE / SCT)

# Cálculo de r
r = np.sum((x - media_x) * (y - media_y)) / (np.sqrt(np.sum((x - media_x) ** 2) * np.sum((y - media_y) ** 2)))

print("Coeficiente de determinación R^2:", r_cuadrado)
print("Coeficiente de correlación r:", r)